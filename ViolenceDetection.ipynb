{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea20cb39-3e01-41a0-9074-63f639a036c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Violence Detection Model 가중치 로드 성공!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5120</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5120</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5120</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,319,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m5120\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m5120\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m5120\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │     \u001b[38;5;34m1,319,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m16,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m66\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,379,106</span> (5.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,379,106\u001b[0m (5.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,379,106</span> (5.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,379,106\u001b[0m (5.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import TimeDistributed, Dropout, Bidirectional, LSTM, Dense, Flatten\n",
    "\n",
    "# === Violence Detection MoBiLSTM Model ===\n",
    "model = Sequential([\n",
    "    # (1) CNN feature sequence input\n",
    "    TimeDistributed(\n",
    "        Flatten(),  # 입력은 (16, 2, 2, 1280)\n",
    "        input_shape=(16, 2, 2, 1280),\n",
    "        name=\"time_distributed\"\n",
    "    ),\n",
    "    Dropout(0.5, name=\"dropout\"),\n",
    "\n",
    "    # (2) Flatten frame features → sequence\n",
    "    TimeDistributed(Flatten(), name=\"time_distributed_1\"),\n",
    "\n",
    "    # (3) BiLSTM sequence encoder\n",
    "    Bidirectional(LSTM(32, return_sequences=False), name=\"bidirectional\"),\n",
    "    Dropout(0.5, name=\"dropout_1\"),\n",
    "\n",
    "    # (4) Fully-connected classifier\n",
    "    Dense(256, activation='relu', name=\"dense\"),\n",
    "    Dropout(0.5, name=\"dropout_2\"),\n",
    "    Dense(128, activation='relu', name=\"dense_1\"),\n",
    "    Dropout(0.5, name=\"dropout_3\"),\n",
    "    Dense(64, activation='relu', name=\"dense_2\"),\n",
    "    Dropout(0.5, name=\"dropout_4\"),\n",
    "    Dense(32, activation='relu', name=\"dense_3\"),\n",
    "    Dropout(0.5, name=\"dropout_5\"),\n",
    "    Dense(2, activation='softmax', name=\"dense_4\")\n",
    "])\n",
    "\n",
    "# === Load weights ===\n",
    "model.load_weights(\"/Users/jeongjihoon/hackathon/new_violence_detection_model.weights.h5\")\n",
    "\n",
    "print(\"✅ Violence Detection Model 가중치 로드 성공!\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36ceb93d-4393-4e4d-8e91-aededb4d2e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import TimeDistributed, Dropout, Bidirectional, LSTM, Dense, Flatten\n",
    "from tensorflow.keras.applications import MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2f83796-8019-4de1-890c-115fd1275ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1️⃣ 경로 설정 ===\n",
    "VIDEO_PATH = \"/Users/jeongjihoon/Downloads/archive (1)/Real Life Violence Dataset/Violence/V_341.mp4\"\n",
    "OUTPUT_PATH = \"/Users/jeongjihoon/Desktop/output.mp4\"\n",
    "CAPTURE_DIR = \"/Users/jeongjihoon/Desktop/violence_captures\"\n",
    "os.makedirs(CAPTURE_DIR, exist_ok=True)\n",
    "\n",
    "model = Sequential([\n",
    "    TimeDistributed(Flatten(), input_shape=(16, 2, 2, 1280), name=\"time_distributed\"),\n",
    "    Dropout(0.5, name=\"dropout\"),\n",
    "    TimeDistributed(Flatten(), name=\"time_distributed_1\"),\n",
    "    Bidirectional(LSTM(32, return_sequences=False), name=\"bidirectional\"),\n",
    "    Dropout(0.5, name=\"dropout_1\"),\n",
    "    Dense(256, activation=\"relu\", name=\"dense\"),\n",
    "    Dropout(0.5, name=\"dropout_2\"),\n",
    "    Dense(128, activation=\"relu\", name=\"dense_1\"),\n",
    "    Dropout(0.5, name=\"dropout_3\"),\n",
    "    Dense(64, activation=\"relu\", name=\"dense_2\"),\n",
    "    Dropout(0.5, name=\"dropout_4\"),\n",
    "    Dense(32, activation=\"relu\", name=\"dense_3\"),\n",
    "    Dropout(0.5, name=\"dropout_5\"),\n",
    "    Dense(2, activation=\"softmax\", name=\"dense_4\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a01b96f1-8932-43ec-93d5-d411e32ae7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dx/8v7zh4b12256tjldk42q7v880000gn/T/ipykernel_6148/2622149999.py:19: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  feature_extractor = MobileNetV2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature extractor 준비 완료: (None, 2, 2, 1280)\n",
      "✅ Violence Detection 모델 가중치 로드 완료!\n",
      "🎥 폭력 감지 중... (Q로 종료)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🚨 폭력 감지! 캡처 저장됨: /Users/jeongjihoon/Desktop/violence_captures/capture_1.jpg\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🚨 폭력 감지! 캡처 저장됨: /Users/jeongjihoon/Desktop/violence_captures/capture_2.jpg\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🚨 폭력 감지! 캡처 저장됨: /Users/jeongjihoon/Desktop/violence_captures/capture_3.jpg\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🚨 폭력 감지! 캡처 저장됨: /Users/jeongjihoon/Desktop/violence_captures/capture_4.jpg\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🚨 폭력 감지! 캡처 저장됨: /Users/jeongjihoon/Desktop/violence_captures/capture_5.jpg\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🚨 폭력 감지! 캡처 저장됨: /Users/jeongjihoon/Desktop/violence_captures/capture_6.jpg\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🚨 폭력 감지! 캡처 저장됨: /Users/jeongjihoon/Desktop/violence_captures/capture_7.jpg\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🚨 폭력 감지! 캡처 저장됨: /Users/jeongjihoon/Desktop/violence_captures/capture_8.jpg\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "🧩 입력 시퀀스 shape: (1, 16, 2, 2, 1280)\n",
      "✅ 분석 완료!\n",
      "🎞️ 결과 영상 저장: /Users/jeongjihoon/Desktop/output.mp4\n",
      "🖼️ 캡처 이미지 저장 폴더: /Users/jeongjihoon/Desktop/violence_captures\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    TimeDistributed, Dropout, Bidirectional, LSTM,\n",
    "    Dense, Flatten\n",
    ")\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "# === 1️⃣ 경로 설정 ===\n",
    "VIDEO_PATH = \"/Users/jeongjihoon/Downloads/archive (1)/Real Life Violence Dataset/Violence/V_341.mp4\"  # 분석할 영상\n",
    "OUTPUT_PATH = \"/Users/jeongjihoon/Desktop/output.mp4\"     # 결과 영상 저장 경로\n",
    "CAPTURE_DIR = \"/Users/jeongjihoon/Desktop/violence_captures\"  # 폭력 캡처 저장 폴더\n",
    "os.makedirs(CAPTURE_DIR, exist_ok=True)\n",
    "\n",
    "# === 2️⃣ Feature extractor (MobileNetV2) ===\n",
    "feature_extractor = MobileNetV2(\n",
    "    weights='imagenet',\n",
    "    include_top=False,     # fully connected 제거\n",
    "    pooling=None,          # (2,2,1280) 그대로 유지\n",
    "    input_shape=(64, 64, 3)\n",
    ")\n",
    "print(\"✅ Feature extractor 준비 완료:\", feature_extractor.output_shape)\n",
    "\n",
    "# === 3️⃣ Violence Detection Model ===\n",
    "model = Sequential([\n",
    "    TimeDistributed(Flatten(), input_shape=(16, 2, 2, 1280), name=\"time_distributed\"),\n",
    "    Dropout(0.5, name='dropout'),\n",
    "    TimeDistributed(Flatten(), name='time_distributed_1'),\n",
    "    Bidirectional(LSTM(32, return_sequences=False), name='bidirectional'),\n",
    "    Dropout(0.5, name='dropout_1'),\n",
    "    Dense(256, activation='relu', name='dense'),\n",
    "    Dropout(0.5, name='dropout_2'),\n",
    "    Dense(128, activation='relu', name='dense_1'),\n",
    "    Dropout(0.5, name='dropout_3'),\n",
    "    Dense(64, activation='relu', name='dense_2'),\n",
    "    Dropout(0.5, name='dropout_4'),\n",
    "    Dense(32, activation='relu', name='dense_3'),\n",
    "    Dropout(0.5, name='dropout_5'),\n",
    "    Dense(2, activation='softmax', name='dense_4')\n",
    "])\n",
    "\n",
    "# === 4️⃣ 가중치 로드 ===\n",
    "model.load_weights(\"/Users/jeongjihoon/hackathon/new_violence_detection_model.weights.h5\")\n",
    "print(\"✅ Violence Detection 모델 가중치 로드 완료!\")\n",
    "\n",
    "# === 5️⃣ 분석 파라미터 ===\n",
    "SEQUENCE_LENGTH = 16\n",
    "IMG_SIZE = (64, 64)\n",
    "frame_buffer = []\n",
    "capture_count = 0\n",
    "MAX_CAPTURES = 8\n",
    "\n",
    "# === 6️⃣ 비디오 로드 ===\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"❌ 비디오 파일을 열 수 없습니다.\")\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(OUTPUT_PATH, fourcc, fps, (width, height))\n",
    "\n",
    "print(\"🎥 폭력 감지 중... (Q로 종료)\")\n",
    "\n",
    "# === 7️⃣ 프레임 분석 루프 ===\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize + Normalize\n",
    "    resized = cv2.resize(frame, IMG_SIZE)\n",
    "    resized = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)\n",
    "    resized = np.expand_dims(resized, axis=0) / 255.0\n",
    "\n",
    "    # === MobileNetV2 Feature 추출 ===\n",
    "    features = feature_extractor.predict(resized, verbose=0)  # (1, 2, 2, 1280)\n",
    "    features = np.squeeze(features, axis=0)                   # (2, 2, 1280)\n",
    "    frame_buffer.append(features)\n",
    "\n",
    "    if len(frame_buffer) > SEQUENCE_LENGTH:\n",
    "        frame_buffer.pop(0)\n",
    "\n",
    "    label_text = \"Analyzing...\"\n",
    "    color = (255, 255, 0)\n",
    "\n",
    "    # === 16프레임 단위로 폭력 판별 ===\n",
    "    if len(frame_buffer) == SEQUENCE_LENGTH:\n",
    "        sequence = np.expand_dims(np.array(frame_buffer, dtype=np.float32), axis=0)  # (1,16,2,2,1280)\n",
    "        print(\"🧩 입력 시퀀스 shape:\", sequence.shape)\n",
    "\n",
    "        preds = model.predict(sequence, verbose=0)\n",
    "        pred_label = np.argmax(preds)\n",
    "        confidence = preds[0][pred_label]\n",
    "\n",
    "        # === 폭력 감지 ===\n",
    "        if pred_label == 1 and confidence > 0.7:\n",
    "            label_text = f\" VIOLENCE DETECTED ({confidence*100:.1f}%)\"\n",
    "            color = (0, 0, 255)\n",
    "\n",
    "            if capture_count < MAX_CAPTURES:\n",
    "                capture_path = os.path.join(CAPTURE_DIR, f\"capture_{capture_count+1}.jpg\")\n",
    "                cv2.imwrite(capture_path, frame)\n",
    "                capture_count += 1\n",
    "                print(f\"🚨 폭력 감지! 캡처 저장됨: {capture_path}\")\n",
    "        else:\n",
    "            label_text = f\" SAFE ({confidence*100:.1f}%)\"\n",
    "            color = (0, 255, 0)\n",
    "\n",
    "    # === 결과 표시 및 저장 ===\n",
    "    cv2.putText(frame, label_text, (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 3)\n",
    "    out.write(frame)\n",
    "    cv2.imshow(\"Violence Detection Demo\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# === 8️⃣ 종료 ===\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"✅ 분석 완료!\")\n",
    "print(f\"🎞️ 결과 영상 저장: {OUTPUT_PATH}\")\n",
    "print(f\"🖼️ 캡처 이미지 저장 폴더: {CAPTURE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72be8f0c-5753-4a24-b69f-29f4dcfdce4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chardet in /opt/anaconda3/envs/keras2/lib/python3.9/site-packages (5.2.0)\n",
      "Requirement already satisfied: charset-normalizer in /opt/anaconda3/envs/keras2/lib/python3.9/site-packages (3.3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install chardet charset-normalizer\n",
    "#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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42a18a7f-b5c5-42d6-9cf9-c90df278c843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ API 요청 실패 (404)\n",
      "Not Found\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# ✅ 새 API 엔드포인트\n",
    "API_URL = \"https://api-inference.huggingface.co/models/Qwen/Qwen2-VL-7B-Instruct\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}  # 토큰 그대로 사용 가능\n",
    "\n",
    "image_paths = [\n",
    "    \"/Users/jeongjihoon/Desktop/violence_captures/capture_1.jpg\",\n",
    "    \"/Users/jeongjihoon/Desktop/violence_captures/capture_2.jpg\",\n",
    "    \"/Users/jeongjihoon/Desktop/violence_captures/capture_3.jpg\",\n",
    "    \"/Users/jeongjihoon/Desktop/violence_captures/capture_4.jpg\",\n",
    "    \"/Users/jeongjihoon/Desktop/violence_captures/capture_5.jpg\",\n",
    "    \"/Users/jeongjihoon/Desktop/violence_captures/capture_6.jpg\",\n",
    "    \"/Users/jeongjihoon/Desktop/violence_captures/capture_7.jpg\",\n",
    "    \"/Users/jeongjihoon/Desktop/violence_captures/capture_8.jpg\"\n",
    "]\n",
    "\n",
    "data = {\n",
    "    \"inputs\": {\n",
    "        \"text\": (\n",
    "            \"이 8장의 CCTV 이미지를 분석하여 폭력이나 위협적 상황이 있다면 \"\n",
    "            \"6하원칙(누가, 언제, 어디서, 무엇을, 어떻게, 왜)에 따라 \"\n",
    "            \"경찰 보고서 형식으로 작성하라.\"\n",
    "        )\n",
    "    }\n",
    "}\n",
    "\n",
    "files = [(\"images\", (f\"frame{i}.jpg\", open(path, \"rb\"), \"image/jpeg\")) for i, path in enumerate(image_paths)]\n",
    "\n",
    "response = requests.post(API_URL, headers=headers, data={\"inputs\": json.dumps(data)}, files=files, timeout=120)\n",
    "\n",
    "if response.status_code != 200:\n",
    "    print(f\"❌ API 요청 실패 ({response.status_code})\")\n",
    "    print(response.text)\n",
    "else:\n",
    "    try:\n",
    "        print(json.dumps(response.json(), indent=2, ensure_ascii=False))\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"⚠️ 응답이 JSON 형식이 아닙니다.\")\n",
    "        print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d3827f76-44c4-4f15-8ef3-6ae678a2b8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 결과:\n",
      "\n",
      "양쪽에서 남성이 서로 무언가에 항의하는 듯이 서로를 이리저리 패싸우고 있습니다. 두 남성은 각각 다른 방향으로 이동하며 서로를 향해 몸을 굴리고 있습니다. 배경에는 버스와 건물이 보이며, 이는 아마도 도시의 버스 정류장이나 같은 곳으로 보입니다. 이들의 행동은 경찰 조사의 대상이 될 만한 상황으로 보입니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "import mimetypes  # 파일 타입 추측용\n",
    "\n",
    "# --- 1. 로컬 이미지를 Base64로 인코딩하는 함수 ---\n",
    "def encode_image_to_base64(image_path):\n",
    "    \"\"\"로컬 이미지 파일을 읽어 Base64 데이터 URI로 인코딩합니다.\"\"\"\n",
    "    mime_type, _ = mimetypes.guess_type(image_path)\n",
    "    if not mime_type or not mime_type.startswith('image'):\n",
    "        raise ValueError(\"알 수 없거나 유효하지 않은 이미지 파일입니다.\")\n",
    "\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    \n",
    "    return f\"data:{mime_type};base64,{encoded_string}\"\n",
    "\n",
    "# --- 2. OpenAI(Hugging Face Router) 클라이언트 설정 ---\n",
    "client = OpenAI(\n",
    "    base_url=\"https://router.huggingface.co/v1\",\n",
    "    api_key=os.environ[\"HF_TOKEN\"],\n",
    ")\n",
    "\n",
    "# --- 3. 이미지 경로 ---\n",
    "local_image_path = \"/Users/jeongjihoon/Desktop/violence_captures/capture_1.jpg\"\n",
    "\n",
    "# --- 4. 프롬프트 ---\n",
    "prompt = (\n",
    "    \"다음 이미지는 CCTV에서 포착된 폭력 사건 장면입니다.\\n\"\n",
    "    \"사진 속 상황을 관찰하여, 누가 어떤 행동을 하는지, 장소와 상황의 흐름을 자연스럽게 설명하세요.\\n\"\n",
    "    \"마치 경찰 보고서 초안처럼, 사건의 개요를 객관적이고 간결한 한 문단으로 요약하세요.\\n\"\n",
    "    \"직역형 표현 대신 자연스러운 서술문 형태로 써주세요.\"\n",
    ")\n",
    "\n",
    "# --- 5. 모델 호출 ---\n",
    "try:\n",
    "    base64_image_url = encode_image_to_base64(local_image_path)\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"Qwen/Qwen2.5-VL-7B-Instruct:hyperbolic\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": base64_image_url}},\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    print(\"🧾 결과:\\n\")\n",
    "    # ✅ 핵심 수정: message 객체에서 content를 직접 출력\n",
    "    print(completion.choices[0].message.content)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"오류: '{local_image_path}' 파일을 찾을 수 없습니다.\")\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "efd23a78-b2eb-476d-a9c9-a42117973f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧩 1차 (1~4장) 요약 중...\n",
      "🧩 2차 (5~8장) 요약 중...\n",
      "\n",
      "🧠 최종 사건 요약 생성 중...\n",
      "\n",
      "\n",
      "✅ 최종 사건 요약:\n",
      "\n",
      "남성 A가 차량에 세우는 남성 B를 돕다가 차량 옆을 지나간 남성 C가 폭력 사건을 목격했다. 이 사건은 공공 차량이 주차된 곳에서 피의자와 피해자가 그란지로 달려들어 싸우는 것으로, 피해자는 공개적으로 눈을 맞추며 싸우고 있다. 주변에는 다른 인물들이 관찰하고 있다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "import mimetypes\n",
    "\n",
    "# --- 1. Base64 인코딩 함수 ---\n",
    "def encode_image_to_base64(image_path):\n",
    "    mime_type, _ = mimetypes.guess_type(image_path)\n",
    "    if not mime_type or not mime_type.startswith(\"image\"):\n",
    "        raise ValueError(f\"유효하지 않은 이미지 파일: {image_path}\")\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        encoded = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "    return f\"data:{mime_type};base64,{encoded}\"\n",
    "\n",
    "# --- 2. 클라이언트 설정 ---\n",
    "client = OpenAI(\n",
    "    base_url=\"https://router.huggingface.co/v1\",\n",
    "    api_key=os.environ[\"HF_TOKEN\"],\n",
    ")\n",
    "\n",
    "# --- 3. 이미지 경로 리스트 (총 8장) ---\n",
    "image_folder = \"/Users/jeongjihoon/Desktop/violence_captures\"\n",
    "image_paths = [os.path.join(image_folder, f\"capture_{i}.jpg\") for i in range(1, 9)]\n",
    "\n",
    "# --- 4. 프롬프트 ---\n",
    "prompt = (\n",
    "    \"다음 8장의 이미지는 CCTV에서 연속적으로 포착된 폭력 사건입니다.\\n\"\n",
    "    \"이미지 속 인물의 행동, 위치, 상황 변화를 관찰하여 사건 전체를 자연스럽게 요약하세요.\\n\"\n",
    "    \"한 문단으로 간결하게 작성하고, 불필요한 설명은 제외하세요.\"\n",
    ")\n",
    "\n",
    "# --- 5. 4장씩 나눠서 처리 ---\n",
    "def summarize_images(image_subset):\n",
    "    base64_images = [\n",
    "        {\"type\": \"image_url\", \"image_url\": {\"url\": encode_image_to_base64(p)}}\n",
    "        for p in image_subset\n",
    "    ]\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": prompt}] + base64_images}\n",
    "    ]\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"Qwen/Qwen2.5-VL-7B-Instruct:hyperbolic\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "# --- 6. 두 구간으로 나눠 요청 ---\n",
    "try:\n",
    "    print(\"🧩 1차 (1~4장) 요약 중...\")\n",
    "    summary1 = summarize_images(image_paths[:4])\n",
    "\n",
    "    print(\"🧩 2차 (5~8장) 요약 중...\")\n",
    "    summary2 = summarize_images(image_paths[4:])\n",
    "\n",
    "    # --- 7. 최종 요약 ---\n",
    "    print(\"\\n🧠 최종 사건 요약 생성 중...\\n\")\n",
    "    combined_prompt = (\n",
    "        \"다음은 CCTV 폭력 사건의 두 구간 요약입니다.\\n\"\n",
    "        f\"1️⃣ {summary1}\\n\"\n",
    "        f\"2️⃣ {summary2}\\n\\n\"\n",
    "        \"이 두 내용을 바탕으로, 사건 전체를 한 문단으로 짧고 명확하게 요약하세요.\\n\"\n",
    "        \"사건의 핵심 내용만 남기고 군더더기는 생략하세요.\"\n",
    "    )\n",
    "\n",
    "    final_completion = client.chat.completions.create(\n",
    "        model=\"Qwen/Qwen2.5-VL-7B-Instruct:hyperbolic\",\n",
    "        messages=[{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": combined_prompt}]}],\n",
    "    )\n",
    "\n",
    "    print(\"\\n✅ 최종 사건 요약:\\n\")\n",
    "    print(final_completion.choices[0].message.content)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a204b3-333f-449a-8fc0-00b0a56ba31b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
